{
  "cells": [
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 12,
=======
      "execution_count": null,
>>>>>>> 96-augmentation-for-spectrograms
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-02T15:16:54.139206Z",
          "start_time": "2024-04-02T15:16:54.136296Z"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "DEPENDENCIES_SAVE_PATH = Path('dependencies')\n",
        "SOURCE_CODE_SAVE_PATH = Path('source-code')\n",
        "SOURCE_CODE_PATH = Path('../')\n",
        "\n",
        "UPDATE_DEPENDENCIES = False\n",
        "UPDATE_SOURCE_CODE = True\n",
        "\n",
        "TM_HASH = \"9ccd778ef9e75d71689947f46a874dfb\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Manages Depenedencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download Dependencies and ZIP them"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 13,
=======
      "execution_count": null,
>>>>>>> 96-augmentation-for-spectrograms
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-02T15:16:54.147276Z",
          "start_time": "2024-04-02T15:16:54.140858Z"
        }
      },
      "outputs": [],
      "source": [
        "if UPDATE_DEPENDENCIES:\n",
        "    if os.path.exists(DEPENDENCIES_SAVE_PATH):\n",
        "        print('Cleaning the dependencies folder')\n",
        "        for filename in os.listdir(DEPENDENCIES_SAVE_PATH):\n",
        "            file_path = os.path.join(DEPENDENCIES_SAVE_PATH, filename)\n",
        "            if filename != 'tmp':\n",
        "                if os.path.isfile(file_path):\n",
        "                    os.remove(file_path)\n",
        "                elif os.path.isdir(file_path):\n",
        "                    shutil.rmtree(file_path)\n",
        "    else:\n",
        "        os.makedirs(DEPENDENCIES_SAVE_PATH)\n",
        "\n",
        "    print('Copying the requirements.txt file and excluding -e')\n",
        "    with open(SOURCE_CODE_PATH / 'requirements.txt', 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    with open(DEPENDENCIES_SAVE_PATH / 'requirements.txt', 'w') as f:\n",
        "        for line in lines:\n",
        "            if line.startswith('-e'):\n",
        "                continue\n",
        "            if line.startswith('kaggle'):\n",
        "                continue\n",
        "            f.write(line)\n",
        "\n",
        "    if not os.path.exists(DEPENDENCIES_SAVE_PATH / 'tmp'):\n",
        "        os.makedirs(DEPENDENCIES_SAVE_PATH / 'tmp')\n",
        "    print('Downloading the dependencies')\n",
        "    if not os.path.exists(DEPENDENCIES_SAVE_PATH / 'tmp'):\n",
        "        os.makedirs(DEPENDENCIES_SAVE_PATH / 'tmp')\n",
        "    !pip download -r {DEPENDENCIES_SAVE_PATH / 'requirements.txt'} -d {DEPENDENCIES_SAVE_PATH / 'tmp'}\n",
        "\n",
        "    print('Zipping the downloaded dependencies')\n",
        "    shutil.make_archive(DEPENDENCIES_SAVE_PATH / 'dependencies', 'zip', DEPENDENCIES_SAVE_PATH / 'tmp')\n",
        "    shutil.move(DEPENDENCIES_SAVE_PATH / 'dependencies.zip', DEPENDENCIES_SAVE_PATH / 'dependencies.no_unzip')\n",
        "    shutil.rmtree(DEPENDENCIES_SAVE_PATH / 'tmp')\n",
        "\n",
        "    print('Copying the dataset-metadata.json file')\n",
        "    shutil.copy('dataset-metadata-dependencies.json', DEPENDENCIES_SAVE_PATH / 'dataset-metadata.json')\n",
        "\n",
        "    print('Excluding --find-files in requirements.txt')\n",
        "    with open(DEPENDENCIES_SAVE_PATH / 'requirements.txt', 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    with open(DEPENDENCIES_SAVE_PATH / 'requirements.txt', 'w') as f:\n",
        "        for line in lines:\n",
        "            if line.startswith('--find-links'):\n",
        "                continue\n",
        "            f.write(line)\n",
        "\n",
        "    print('Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upload Dependencies to Kaggle as a Dataset"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 14,
=======
      "execution_count": null,
>>>>>>> 96-augmentation-for-spectrograms
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-02T15:16:54.150668Z",
          "start_time": "2024-04-02T15:16:54.148463Z"
        }
      },
      "outputs": [],
      "source": [
        "if UPDATE_DEPENDENCIES:\n",
        "    # !kaggle datasets create -p ./dependencies\n",
        "    !kaggle datasets version -p ./dependencies -m \"Update Dependencies\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Manage Source Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Copy Source Code and ZIP it"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 15,
=======
      "execution_count": null,
>>>>>>> 96-augmentation-for-spectrograms
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-02T15:16:56.908249Z",
          "start_time": "2024-04-02T15:16:54.151488Z"
        }
      },
      "outputs": [],
      "source": [
        "if UPDATE_SOURCE_CODE:\n",
        "    if os.path.exists(SOURCE_CODE_SAVE_PATH):\n",
        "        shutil.rmtree(SOURCE_CODE_SAVE_PATH)\n",
        "    os.mkdir(SOURCE_CODE_SAVE_PATH)\n",
        "\n",
        "    # Copy Source Code to submission/source_code\n",
        "    relevant_files = ['src/', 'conf/', 'submit.py']\n",
        "    if TM_HASH is None:\n",
        "        relevant_files.append('tm/')\n",
        "    else:\n",
        "        # Ask for user confirmation if the hash is correct\n",
        "        answer = input(f\"Is the specified TM hash {TM_HASH} correct? (y/n): \")\n",
        "        if answer.lower() != 'y':\n",
        "            print('Please specify the correct TM hash')\n",
        "            exit(1)\n",
        "        \n",
        "        found_one = False\n",
        "        tm = os.listdir(SOURCE_CODE_PATH / 'tm')\n",
        "        for file in tm:\n",
        "            if file.startswith(TM_HASH):\n",
        "                found_one = True\n",
        "                relevant_files.append('tm/' + file)\n",
        "        if not found_one:\n",
        "            print(f'No files found with the specified hash {TM_HASH}')\n",
        "            exit(1)\n",
        "    \n",
        "    # Exclude __pycache__ from copying\n",
        "    exluded_files = ['__pycache__']\n",
        "    \n",
        "    # Copy relevant files to tmp\n",
        "    for file in relevant_files:\n",
        "        if os.path.isdir(SOURCE_CODE_PATH / file):\n",
        "            # Copy directory, skip excluded files with shutil\n",
        "            shutil.copytree(SOURCE_CODE_PATH / file, SOURCE_CODE_SAVE_PATH / \"tmp\" / file, ignore=shutil.ignore_patterns(*exluded_files))\n",
        "        else:\n",
        "            # Copy file and create directories if not exist\n",
        "            os.makedirs(SOURCE_CODE_SAVE_PATH / \"tmp\" / os.path.dirname(file), exist_ok=True)\n",
        "            shutil.copy(SOURCE_CODE_PATH / file, SOURCE_CODE_SAVE_PATH / \"tmp\" / file)\n",
        "\n",
        "    # Zip source_code\n",
        "    shutil.make_archive(SOURCE_CODE_SAVE_PATH / 'source-code', 'zip', SOURCE_CODE_SAVE_PATH / \"tmp\")\n",
        "    shutil.rmtree(SOURCE_CODE_SAVE_PATH / \"tmp\")\n",
        "\n",
        "    # # Copy dataset-metadata.json to submission\n",
        "    shutil.copy('dataset-metadata-source-code.json', SOURCE_CODE_SAVE_PATH / 'dataset-metadata.json')\n",
        "\n",
        "    print('Submission files saved to source_code')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upload Source Code"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 16,
=======
      "execution_count": null,
>>>>>>> 96-augmentation-for-spectrograms
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-02T15:17:01.533036Z",
          "start_time": "2024-04-02T15:16:56.909432Z"
        }
      },
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting upload for file source-code.zip\r\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.7 / client 1.6.6)\r\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 74.4M/74.4M [00:02<00:00, 26.5MB/s]\r\n",
            "Upload successful: source-code.zip (74MB)\r\n",
            "Dataset version is being created. Please check progress at https://www.kaggle.com/justanotherariel/epoch-hms-source-code\r\n"
          ]
        }
      ],
=======
      "outputs": [],
>>>>>>> 96-augmentation-for-spectrograms
      "source": [
        "if UPDATE_SOURCE_CODE:\n",
        "    # !kaggle datasets create -p ./source-code\n",
        "    !kaggle datasets version -p ./source-code -m \"Update Source Code\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
