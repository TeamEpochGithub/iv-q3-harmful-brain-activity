{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T21:38:33.948464Z",
     "start_time": "2024-03-30T21:38:33.944642Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "DEPENDENCIES_SAVE_PATH = Path('dependencies')\n",
    "SOURCE_CODE_SAVE_PATH = Path('source-code')\n",
    "SOURCE_CODE_PATH = Path('../')\n",
    "#pip install -r C://Users//Tolga//Desktop//EPOCH-IV//q3-harmful-brain-activity//submission//dependencies//requirements.txt --no-index --find-links=file://C://Users//Tolga//Desktop//EPOCH-IV//q3-harmful-brain-activity//submission//dependencies//tmp\n",
    "UPDATE_DEPENDENCIES = False\n",
    "UPDATE_SOURCE_CODE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manages Depenedencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dependencies and ZIP them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T21:38:33.984710Z",
     "start_time": "2024-03-30T21:38:33.958489Z"
    }
   },
   "outputs": [],
   "source": [
    "if UPDATE_DEPENDENCIES:\n",
    "    if os.path.exists(DEPENDENCIES_SAVE_PATH):\n",
    "        print('Cleaning the dependencies folder')\n",
    "        for filename in os.listdir(DEPENDENCIES_SAVE_PATH):\n",
    "            file_path = os.path.join(DEPENDENCIES_SAVE_PATH, filename)\n",
    "            if filename != 'tmp':\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.remove(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "    else:\n",
    "        os.makedirs(DEPENDENCIES_SAVE_PATH)\n",
    "\n",
    "    print('Copying the requirements.txt file and excluding -e')\n",
    "    with open(SOURCE_CODE_PATH / 'requirements.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    with open(DEPENDENCIES_SAVE_PATH / 'requirements.txt', 'w') as f:\n",
    "        for line in lines:\n",
    "            if line.startswith('-e'):\n",
    "                continue\n",
    "            if line.startswith('kaggle'):\n",
    "                continue\n",
    "            f.write(line)\n",
    "\n",
    "    if not os.path.exists(DEPENDENCIES_SAVE_PATH / 'tmp'):\n",
    "        os.makedirs(DEPENDENCIES_SAVE_PATH / 'tmp')\n",
    "    print('Downloading the dependencies')\n",
    "    if not os.path.exists(DEPENDENCIES_SAVE_PATH / 'tmp'):\n",
    "        os.makedirs(DEPENDENCIES_SAVE_PATH / 'tmp')\n",
    "    !pip download -r {DEPENDENCIES_SAVE_PATH / 'requirements.txt'} -d {DEPENDENCIES_SAVE_PATH / 'tmp'}\n",
    "\n",
    "    print('Zipping the downloaded dependencies')\n",
    "    shutil.make_archive(DEPENDENCIES_SAVE_PATH / 'dependencies', 'zip', DEPENDENCIES_SAVE_PATH / 'tmp')\n",
    "    shutil.move(DEPENDENCIES_SAVE_PATH / 'dependencies.zip', DEPENDENCIES_SAVE_PATH / 'dependencies.no_unzip')\n",
    "    shutil.rmtree(DEPENDENCIES_SAVE_PATH / 'tmp')\n",
    "\n",
    "    print('Copying the dataset-metadata.json file')\n",
    "    shutil.copy('dataset-metadata-dependencies.json', DEPENDENCIES_SAVE_PATH / 'dataset-metadata.json')\n",
    "\n",
    "    print('Excluding --find-files in requirements.txt')\n",
    "    with open(DEPENDENCIES_SAVE_PATH / 'requirements.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    with open(DEPENDENCIES_SAVE_PATH / 'requirements.txt', 'w') as f:\n",
    "        for line in lines:\n",
    "            if line.startswith('--find-links'):\n",
    "                continue\n",
    "            f.write(line)\n",
    "\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Dependencies to Kaggle as a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T21:38:34.025065Z",
     "start_time": "2024-03-30T21:38:33.985527Z"
    }
   },
   "outputs": [],
   "source": [
    "if UPDATE_DEPENDENCIES:\n",
    "    # !kaggle datasets create -p ./dependencies\n",
    "    !kaggle datasets version -p ./dependencies -m \"Update Dependencies\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Source Code and ZIP it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T21:39:28.600361Z",
     "start_time": "2024-03-30T21:38:34.025869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission files saved to source_code\n"
     ]
    }
   ],
   "source": [
    "if UPDATE_SOURCE_CODE:\n",
    "    if os.path.exists(SOURCE_CODE_SAVE_PATH):\n",
    "        shutil.rmtree(SOURCE_CODE_SAVE_PATH)\n",
    "    os.mkdir(SOURCE_CODE_SAVE_PATH)\n",
    "\n",
    "    # Copy Source Code to submission/source_code\n",
    "    relevant_files = ['src/', 'conf/', 'tm/', 'submit.py']\n",
    "    exluded_files = ['__pycache__']\n",
    "    for file in relevant_files:\n",
    "        if os.path.isdir(SOURCE_CODE_PATH / file):\n",
    "            # Copy directory, skip excluded files with shutil\n",
    "            shutil.copytree(SOURCE_CODE_PATH / file, SOURCE_CODE_SAVE_PATH / \"tmp\" / file, ignore=shutil.ignore_patterns(*exluded_files))\n",
    "        else:\n",
    "            # Copy file\n",
    "            shutil.copy(SOURCE_CODE_PATH / file, SOURCE_CODE_SAVE_PATH / \"tmp\" / file)\n",
    "\n",
    "    # Zip source_code\n",
    "    shutil.make_archive(SOURCE_CODE_SAVE_PATH / 'source-code', 'zip', SOURCE_CODE_SAVE_PATH / \"tmp\")\n",
    "    shutil.rmtree(SOURCE_CODE_SAVE_PATH / \"tmp\")\n",
    "\n",
    "    # Copy dataset-metadata.json to submission\n",
    "    shutil.copy('dataset-metadata-source-code.json', SOURCE_CODE_SAVE_PATH / 'dataset-metadata.json')\n",
    "\n",
    "    print('Submission files saved to source_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T21:40:17.361821Z",
     "start_time": "2024-03-30T21:39:28.601290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/hugo/.kaggle/kaggle.json'\r\n",
      "Starting upload for file source-code.zip\r\n",
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.7 / client 1.6.6)\r\n",
      "100%|██████████████████████████████████████| 1.89G/1.89G [00:47<00:00, 43.1MB/s]\r\n",
      "Upload successful: source-code.zip (2GB)\r\n",
      "Dataset version is being created. Please check progress at https://www.kaggle.com/justanotherariel/epoch-hms-source-code\r\n"
     ]
    }
   ],
   "source": [
    "if UPDATE_SOURCE_CODE:\n",
    "    # !kaggle datasets create -p ./source-code\n",
    "    !kaggle datasets version -p ./source-code -m \"Update Source Code\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
