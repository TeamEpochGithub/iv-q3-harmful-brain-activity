defaults:
  - pipeline/default@_here_
  - _self_

x_sys:
  steps:

    #
    # Kaggle Spectrogram Transformation
    #

    - _target_: src.modules.transformation.clip.Clip
      kaggle_spec: true
      lower: 0.01
      upper: 3000

    - _target_: src.modules.transformation.spectrogram.log.Log
      kaggle_spec: true

    - _target_: src.modules.transformation.spectrogram.standardize.Standardize
      kaggle_spec: true

    - _target_: src.modules.transformation.nantozero.NaNToZero
      kaggle_spec: true

    - _target_: src.modules.transformation.spectrogram.pad.Pad
      kaggle_spec: true
      pad_list: [0, 0, 14, 14]

    #
    # EEG Transformation
    #

    - _target_: src.modules.transformation.clip.Clip
      eeg: true
      lower: -1024
      upper: 1024

    - _target_: src.modules.transformation.nantozero.NaNToZero
      eeg: true

    #
    # EEG Spectrogram Transformation
    #

    - _target_: src.modules.transformation.spectrogram.eeg_to_spectrogram.EEGToSpectrogram
      size: [100, 256]
      fitting_method: 'crop'

    - _target_: src.modules.transformation.spectrogram.pad.Pad
      eeg_spec: true
      pad_list: [0, 0, 14, 14]


train_sys:
  steps:
    - _target_: src.modules.training.main_trainer.MainTrainer
      model_name: "Chris-512"
      epochs: 10
      batch_size: 16
      patience: 10

      two_stage: true
      two_stage_evaluator_threshold: 3
      two_stage_split_test: true
      two_stage_pretrain_full: true

      model:
        _target_: src.modules.training.models.timm.Timm
        in_channels: 3
        out_channels: 6
        model_name: "efficientnet_b0"

      optimizer:
        _target_: functools.partial
        _args_:
          - _target_: hydra.utils.get_class
            path: torch.optim.AdamW
        lr: 1e-2

      criterion:
        _target_: src.modules.training.losses.kldiv_logits.CustomKLDivLogitsLoss
        reduction: "batchmean"
        weighted: false

      dataset_args:
        subsample_method: "running_random"
        data_type: "custom"
        get_item_custom:
          _target_: src.modules.training.datasets.get_item.chris.ChrisGetItem
          use_kaggle_spec: true
          use_eeg_spec: true
          eeg_spec_augmentations:
            - _target_: src.modules.training.augmentations.spectrogram.frequency_mask.FrequencyMask
              freq_mask_param: 25
              apply_x_times: 2
              iid_masks: true
              p: 0.4
            - _target_: src.modules.training.augmentations.spectrogram.time_mask.TimeMask
              time_mask_param: 30
              apply_x_times: 1
              iid_masks: true
              p: 0.2
          kaggle_spec_augmentations:
            - _target_: src.modules.training.augmentations.spectrogram.frequency_mask.FrequencyMask
              freq_mask_param: 25
              apply_x_times: 2
              iid_masks: true
              p: 0.4
            - _target_: src.modules.training.augmentations.spectrogram.time_mask.TimeMask
              time_mask_param: 30
              apply_x_times: 1
              iid_masks: true
              p: 0.2

      # scheduler:
      #   _target_: functools.partial
      #   _args_:
      #     - _target_: hydra.utils.get_class
      #       path: timm.scheduler.multistep_lr.MultiStepLRScheduler
      #   decay_t: [5, 10, 15]
      #   decay_rate: 0.5
      #   warmup_lr_init: 0.01
      #   warmup_t: 2
      # scheduler:
      #   _target_: functools.partial
      #   _args_:
      #     - _target_: hydra.utils.get_class
      #       path: timm.scheduler.cosine_lr.CosineLRScheduler
      #   t_initial: 5
      #   lr_min: 1e-5
      #   warmup_lr_init: 1e-2
      #   warmup_t: 2
      # scheduler:
      #   _target_: functools.partial
      #   _args_:
      #     - _target_: hydra.utils.get_class
      #       path: timm.scheduler.plateau_lr.PlateauLRScheduler
      #   mode: "min"
      #   warmup_t: -1
      #   patience_t: 5
      #   lr_min: 1e-5

      revert_to_best: true
      scheduler:
        _target_: functools.partial
        _args_:
          - _target_: hydra.utils.get_class
            path: torch.optim.lr_scheduler.ReduceLROnPlateau
        mode: "min"
        factor: 0.1
        patience: 3
        threshold: 0.1
        threshold_mode: "rel"
        cooldown: 0
        min_lr: 1e-5
        eps: 1e-8

    - _target_: src.modules.training.postprocessing.softmax.Softmax
    - _target_: src.modules.training.postprocessing.smooth_patient.SmoothPatient
      smooth_factor: 0.09
