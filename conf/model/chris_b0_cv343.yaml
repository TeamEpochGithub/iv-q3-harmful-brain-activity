defaults:
  - pipeline/default@_here_
  - _self_

x_sys:
  steps:

    #
    # Kaggle Spectrogram Transformation
    #

    - _target_: src.modules.transformation.clip.Clip
      kaggle_spec: true
      lower: 0.01
      upper: 3000

    - _target_: src.modules.transformation.spectrogram.log.Log
      kaggle_spec: true

    - _target_: src.modules.transformation.spectrogram.standardize.Standardize
      kaggle_spec: true

    - _target_: src.modules.transformation.nantozero.NaNToZero
      kaggle_spec: true

    - _target_: src.modules.transformation.spectrogram.pad.Pad
      kaggle_spec: true
      pad_list: [0, 0, 14, 14]

    #
    # EEG Transformation
    #

    - _target_: src.modules.transformation.clip.Clip
      eeg: true
      lower: -1024
      upper: 1024

    - _target_: src.modules.transformation.nantozero.NaNToZero
      eeg: true

    #
    # EEG Spectrogram Transformation
    #

    - _target_: src.modules.transformation.spectrogram.eeg_to_spectrogram.EEGToSpectrogram
      size: [100, 256]
      fmax: 25
      fitting_method: 'crop'

    - _target_: src.modules.transformation.spectrogram.standardize.Standardize
      eeg_spec: true

    - _target_: src.modules.transformation.spectrogram.pad.Pad
      eeg_spec: true
      pad_list: [0, 0, 14, 14]


train_sys:
  steps:
    - _target_: src.modules.training.main_trainer.MainTrainer
      model_name: "Chris-512"
      epochs: 24
      batch_size: 32
      patience: 15

      two_stage: true
      two_stage_evaluator_threshold: 9
      two_stage_split_test: true
      two_stage_pretrain_full: true

      model:
        _target_: src.modules.training.models.timm.Timm
        in_channels: 3
        out_channels: 6
        model_name: "efficientnet_b0"

      optimizer:
        _target_: functools.partial
        _args_:
          - _target_: hydra.utils.get_class
            path: torch.optim.AdamW
        lr: 0.002878410457193373

      criterion:
        _target_: src.modules.training.losses.kldiv_logits.CustomKLDivLogitsLoss
        reduction: "batchmean"
        weighted: false

      dataset_args:
        subsample_method: "running_random"
        data_type: "custom"
        get_item_custom:
          _target_: src.modules.training.datasets.get_item.chris.ChrisGetItem
          use_kaggle_spec: true
          use_eeg_spec: true
          eeg_spec_augmentations:
            - _target_: src.modules.training.augmentations.spectrogram.frequency_mask.FrequencyMask
              freq_mask_param: 25
              apply_x_times: 2
              iid_masks: true
              p: 0.5
            - _target_: src.modules.training.augmentations.spectrogram.time_mask.TimeMask
              time_mask_param: 40
              apply_x_times: 1
              iid_masks: true
              p: 0.3
          kaggle_spec_augmentations:
            - _target_: src.modules.training.augmentations.spectrogram.frequency_mask.FrequencyMask
              freq_mask_param: 25
              apply_x_times: 2
              iid_masks: true
              p: 0.5
            - _target_: src.modules.training.augmentations.spectrogram.time_mask.TimeMask
              time_mask_param: 40
              apply_x_times: 1
              iid_masks: true
              p: 0.3

      # scheduler:
      #   _target_: functools.partial
      #   _args_:
      #     - _target_: hydra.utils.get_class
      #       path: timm.scheduler.multistep_lr.MultiStepLRScheduler
      #   decay_t: [5, 10, 15]
      #   decay_rate: 0.5
      #   warmup_lr_init: 0.01
      #   warmup_t: 2
      scheduler:
        _target_: functools.partial
        _args_:
          - _target_: hydra.utils.get_class
            path: timm.scheduler.cosine_lr.CosineLRScheduler
        warmup_t: 4
        warmup_lr_init: 0.00006106441594795696
        t_initial: 54
        cycle_mul: 0.7
        cycle_decay: 0.2
        cycle_limit: 2

      # revert_to_best: true
      # scheduler:
      #   _target_: functools.partial
      #   _args_:
      #     - _target_: hydra.utils.get_class
      #       path: torch.optim.lr_scheduler.ReduceLROnPlateau
      #   mode: "min"
      #   factor: 0.1
      #   patience: 3
      #   threshold: 0.1
      #   threshold_mode: "rel"
      #   cooldown: 0
      #   min_lr: 1e-5
      #   eps: 1e-8

    - _target_: src.modules.training.postprocessing.softmax.Softmax
    - _target_: src.modules.training.postprocessing.smooth_patient.SmoothPatient
      smooth_factor: 0.09
