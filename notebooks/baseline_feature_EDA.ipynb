{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the folder train eegs has a lot of parquet files. Read each of them and store the results in a dataframe\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import dask\n",
    "dask.config.set({'dataframe.query-planning': True})\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/raw/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the patient ids are the same for all unique eeg_ids\n",
    "different_id_eeg_ids = train.groupby('eeg_id').progress_apply(lambda x: (x.loc[:, 'patient_id'].nunique() != 1))\n",
    "different_id_eeg_ids = different_id_eeg_ids[different_id_eeg_ids].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(different_id_eeg_ids)} eeg_ids with different patient_ids')\n",
    "print(f'The eeg_ids are {different_id_eeg_ids}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the last 6 columns are the same for all unique eeg_ids\n",
    "different_labels_eeg_ids = train.groupby('eeg_id').progress_apply(lambda x: (x.iloc[:, -6:].nunique() != 1).any())\n",
    "different_labels_eeg_ids = different_labels_eeg_ids[different_labels_eeg_ids].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(different_labels_eeg_ids)} eeg_ids with different labels in the last 6 columns')\n",
    "print(f'These eeg_ids are: {different_labels_eeg_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['eeg_id'].isin(different_labels_eeg_ids)].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['eeg_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the first eeg file\n",
    "eeg = pq.read_table(f\"../data/raw/train_eegs/{train['eeg_id'].unique()[0]}.parquet\").to_pandas()\n",
    "eeg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each row in train, read the corresponding eeg file and extract the 50*200 samples from each eeg_label offset using groupby\n",
    "# and apply\n",
    "import pickle\n",
    "\n",
    "def get_eegs(x, all_eegs, moving_max):\n",
    "    eeg = pq.read_table(f\"../data/raw/train_eegs/{x.eeg_id.iloc[0]}.parquet\").to_pandas()\n",
    "    all_eegs[x.eeg_id.iloc[0]] = eeg\n",
    "    moving_max[0] = max(len(eeg), moving_max[0])\n",
    "\n",
    "\n",
    "\n",
    "all_eegs = dict()\n",
    "moving_max = np.array([0])\n",
    "# read the spectrgormas per eeg id and extract all the 50*200 samples starting from each eeg label offset\n",
    "# If the pickle file exists, load it, otherwise, create it\n",
    "if os.path.exists('all_eegs.pkl'):\n",
    "    all_eegs = pickle.load(open('all_eegs.pkl', 'rb'))\n",
    "else:\n",
    "    train.groupby('eeg_id').progress_apply(lambda x: get_eegs(x, all_eegs, moving_max))\n",
    "    print('Saving all_eegs to pickle file')\n",
    "    with open('all_eegs.pkl', 'wb') as f:\n",
    "        pickle.dump(all_eegs, f)\n",
    "    print('all_eegs saved to pickle file')\n",
    "print(moving_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offsets(x, all_offsets):\n",
    "    all_offsets[x.eeg_id.iloc[0]] = list(map(int, x.eeg_label_offset_seconds.reset_index(drop=True).tolist()))\n",
    "\n",
    "\n",
    "all_offsets = dict()\n",
    "# read the spectrgormas per eeg id and extract all the 50*200 samples starting from each eeg label offset\n",
    "train.groupby('eeg_id').progress_apply(lambda x: get_offsets(x, all_offsets))\n",
    "len(all_offsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_offsets[11127485]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a pytorch dataset\n",
    "from scipy.signal import decimate\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import time\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, all_eegs, metadata):\n",
    "        self.all_eegs = all_eegs\n",
    "        self.metadata = metadata\n",
    "        self.column_names = None\n",
    "        self.label_names = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # get the eeg id from the idx in the metadata\n",
    "        eeg_id = self.metadata.iloc[idx]['eeg_id']\n",
    "        eeg_label_offset_seconds = int(self.metadata.iloc[idx]['eeg_label_offset_seconds'])\n",
    "        eeg = self.all_eegs[eeg_id]\n",
    "        eeg = eeg.iloc[eeg_label_offset_seconds*200:eeg_label_offset_seconds*200 + 50 * 200, :]\n",
    "        self.column_names = eeg.columns\n",
    "        # set nans in eegto 0 if there are any\n",
    "        eeg = eeg.fillna(0)\n",
    "        self.label_names = self.metadata.columns[-6:]\n",
    "        labels = self.metadata.iloc[idx, -6:]\n",
    "        labels /= sum(labels)\n",
    "        eeg_arr = eeg.to_numpy(dtype=np.float32)\n",
    "        labels_arr = labels.to_numpy(dtype=np.float32)\n",
    "        return torch.from_numpy(eeg_arr), torch.from_numpy(labels_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the eeg dataset\n",
    "eeg_dataset = EEGDataset(all_eegs, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eeg_dataset.column_names)\n",
    "print(eeg_dataset.label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the dataset\n",
    "eeg, labels = eeg_dataset[27]\n",
    "print(eeg_dataset.column_names)\n",
    "eeg = eeg.numpy()\n",
    "labels = labels.numpy()\n",
    "# remove the mean from each column of eeg\n",
    "eeg -= eeg.mean(axis=0)\n",
    "# plot the EEGs\n",
    "print(eeg_dataset.label_names)\n",
    "print(labels)\n",
    "# make 2 subfigures\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "# plot the EEGs\n",
    "ax[0].plot(eeg[:,:])\n",
    "# take the rfft of each column in the eegs\n",
    "eeg_fft = np.fft.rfft(eeg[:,:], axis=0)\n",
    "# plot the fft of the EEGs\n",
    "ax[1].plot(np.linspace(0, 200/2, len(eeg_fft)), np.abs(eeg_fft))\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After application of the lowpass filter, the 60Hz noise is removed from the EEGs\n",
    "# Now subsample the eeg by a factor of 10 by using a decimation filter to also apply an anti aliasing filter\n",
    "from scipy.signal import decimate\n",
    "eeg_decimated = decimate(eeg[:,:], 5, axis=0)\n",
    "\n",
    "decimated_eeg_fft = np.fft.rfft(eeg_decimated, axis=0)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "# loop over to plot the individual channels\n",
    "for i in range(eeg.shape[1]):\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(eeg[:,:])), y=eeg[:,i]))\n",
    "fig.show()\n",
    "#Alos plot the fft results using plotly\n",
    "fig = go.Figure()\n",
    "# loop over to plot the individual channels\n",
    "for i in range(eeg_fft.shape[1]):\n",
    "    fig.add_trace(go.Scatter(x=np.linspace(0, 200/10, len(decimated_eeg_fft)), y=np.abs(decimated_eeg_fft[:,i])))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import firwin\n",
    "\n",
    "# Filter specifications\n",
    "sample_rate = 200  # Example sample rate in Hz\n",
    "cutoff_frequency = 17  # Desired cutoff frequency of the low-pass filter in Hz\n",
    "numtaps = 101  # Number of taps in the FIR filter, determines the filter's length and complexity\n",
    "\n",
    "# Design the low-pass FIR filter using the window method\n",
    "fir_coefficients = firwin(numtaps, cutoff_frequency, fs=sample_rate, window='hamming')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming 'eeg' is your EEG data as a PyTorch tensor of shape (time, channels) on the CPU\n",
    "\n",
    "# Transfer EEG data to GPU\n",
    "eeg_gpu = torch.from_numpy(np.copy(eeg)).to('cuda')\n",
    "print(eeg_gpu.shape)\n",
    "# Convert FIR coefficients to a PyTorch tensor and transfer to GPU\n",
    "fir_coefficients_tensor = torch.tensor(fir_coefficients, dtype=torch.float32).to('cuda')\n",
    "fir_coefficients_tensor = fir_coefficients_tensor.view(1, 1, -1)  # Reshape for convolution\n",
    "\n",
    "# Reshape EEG data for convolution\n",
    "eeg_gpu_reshaped = eeg_gpu.transpose(0, 1).unsqueeze(1)  # From (time, channels) to (channels, 1, time)\n",
    "\n",
    "# Apply the FIR filter using convolution\n",
    "eeg_filtered = F.conv1d(eeg_gpu_reshaped, fir_coefficients_tensor, padding='same')\n",
    "\n",
    "# Downsample the filtered signal\n",
    "decimation_factor = 5\n",
    "eeg_decimated_tensor = eeg_filtered[:, :, ::decimation_factor].squeeze(1).transpose(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eeg_decimated_tensor.shape)\n",
    "print(eeg_decimated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now convert the tensor to numpy and plot the results\n",
    "eeg_decimated = eeg_decimated_tensor.cpu().numpy()\n",
    "decimated_eeg_fft = np.fft.rfft(eeg_decimated, axis=0)\n",
    "fig = go.Figure()\n",
    "# loop over to plot the individual channels\n",
    "for i in range(eeg_decimated.shape[1]):\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(eeg_decimated[:,:])), y=eeg_decimated[:,i]))\n",
    "fig.show()\n",
    "#Alos plot the fft results using plotly\n",
    "fig = go.Figure()\n",
    "# loop over to plot the individual channels\n",
    "for i in range(eeg_decimated.shape[1]):\n",
    "    fig.add_trace(go.Scatter(x=np.linspace(0, 200/10, len(decimated_eeg_fft)), y=np.abs(decimated_eeg_fft[:,i])))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the spectrogram for each eeg and plot the resulting spectrograms\n",
    "import torchaudio.transforms as T\n",
    "import torchaudio\n",
    "\n",
    "spec = T.Spectrogram(n_fft=511, hop_length=1)\n",
    "\n",
    "for channel in range(eeg.shape[1]):\n",
    "    eeg_chanel = np.copy(eeg_decimated[:,channel])\n",
    "\n",
    "    eeg_tensor = torch.from_numpy(eeg_chanel)\n",
    "\n",
    "    print(eeg_tensor.shape)\n",
    "    # compute and plot the spectrgoram using pcolormesh\n",
    "    spec_tensor = spec(eeg_tensor)\n",
    "    print(spec_tensor.shape)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    plt.pcolormesh(spec_tensor.log2().numpy())\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
